\documentclass[11pt,a4paper]{article}

% ========================================
% PACKAGES
% ========================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}  % Change to your language
\usepackage[margin=2.5cm]{geometry}

% Mathematics
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}

% Graphics and colors
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{tikz}

% Lists and formatting
\usepackage{enumitem}
\usepackage{parskip}
\usepackage{fancyhdr}

% Code listings (if needed)
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algorithmic}

% Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

% ========================================
% THEOREM ENVIRONMENTS
% ========================================
\theoremstyle{definition}
\newtheorem{definition}{Definizione}[section]
\newtheorem{example}{Esempio}[section]
\newtheorem{exercise}{Esercizio}[section]

\theoremstyle{plain}
\newtheorem{theorem}{Teorema}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposizione}
\newtheorem{corollary}[theorem]{Corollario}

\theoremstyle{remark}
\newtheorem*{remark}{Nota}
\newtheorem*{observation}{Osservazione}

% ========================================
% CUSTOM COMMANDS
% ========================================
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathbb{C}}

% ========================================
% HEADER AND FOOTER
% ========================================
\pagestyle{fancy}
\setlength{\headheight}{14pt}
\fancyhf{}
\lhead{\leftmark}
\rhead{AR}
\cfoot{\thepage}

% ========================================
% DOCUMENT INFORMATION
% ========================================
\title{\textbf{Automated Reasoning}\\
\large Artificial Intelligence}
\author{Jacopo Parretti}
\date{I Semester 2025-2026}

% ========================================
% DOCUMENT
% ========================================
\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\part{}


\section{Introduction}

\subsection{Why Study Automated Reasoning?}

Automated Reasoning is a fundamental field of artificial intelligence concerned with the design and implementation of computational procedures that enable machines to solve problems formulated in logical languages. These procedures involve \textbf{logical inference and search}, allowing systems to reason in a deductive manner through mechanical processes.

Since the inception of artificial intelligence at the Dartmouth Conference in 1956, one of the core challenges has been to demonstrate machine intelligence through the automated proving of mathematical and logical theorems. This capability represents a cornerstone of symbolic AI, where knowledge is represented symbolically and stored in computer memory, and systematic procedures are applied to solve complex problems.

\textbf{Theorem proving} traditionally requires human-level mathematical reasoning and insight. The goal of automated reasoning is to mechanize this process, creating algorithms and systems capable of performing logical deduction without human intervention.

A logical language consists of formal symbols and syntactic rules. Within the symbolic approach to artificial intelligence, knowledge is encoded using these symbols, which are stored in computer memory. The system then applies a sequence of mechanical steps to manipulate these symbols and arrive at solutions to the given problems.



\newpage

\section{Historical Foundations and Theoretical Limits}

\subsection{The Hilbert-Turing Perspective}

The foundations of automated reasoning can be traced to fundamental questions in mathematical logic and computability. Since Alan Turing's seminal work on \textit{Turing machines} in 1936, researchers have pursued David Hilbert's 1900 challenge: is it possible to develop a mechanical procedure---executed deterministically by a human computor---capable of solving any mathematical problem?

\textbf{The Entscheidungsproblem}: A central question that emerged from this pursuit asks whether it is possible to define a mechanical method to determine the validity of formulas in first-order logic.

Turing demonstrated that the halting problem is undecidable using Turing machines. This fundamental result can be reduced to the validity problem in first-order logic, providing a negative answer to Hilbert's challenge. This undecidability result forms one of the core theoretical foundations of automated reasoning, establishing fundamental limits on what can be mechanically computed.

\subsection{Practical Applications of Automated Reasoning}

Automated reasoning systems find application across multiple domains requiring formal verification and systematic problem-solving:

\begin{itemize}
    \item \textbf{Planning}: Given an initial state, goal state, and formal model of agent actions, determine a sequence of moves that transforms the initial state into the goal state (utilizing SAT solvers)
    \item \textbf{Scheduling}: Generate temporal arrangements of tasks that satisfy complex temporal and resource constraints
    \item \textbf{Software Analysis and Verification}: Formal methods for ensuring program correctness, including:
        \begin{itemize}
            \item Provable privacy guarantees in security protocols
            \item Verification of distributed algorithms
            \item Analysis of randomized algorithms and their probabilistic properties
        \end{itemize}
    \item \textbf{Hybrid Approaches}: Integration of automated reasoning with machine learning techniques for enhanced problem-solving capabilities
\end{itemize}

These applications demonstrate the practical utility of automated reasoning in solving complex real-world problems that require rigorous logical analysis and systematic exploration of solution spaces.


\section{Core Problems in Automated Reasoning}

Automated reasoning fundamentally addresses three interconnected classes of decision problems in mathematical logic, each representing a distinct challenge in determining the truth properties of logical formulas.

\subsection{Satisfiability Problems}

A satisfiability problem (SAT) concerns determining whether a given logical formula has a truth assignment that makes it true. Formally, for a formula $\phi$ with free variables, we seek to determine if there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models \phi$. This represents the existence problem---does there exist a model making the formula true?

\subsection{Validity Problems}

In contrast to satisfiability, validity problems ask whether a formula holds true under all possible interpretations. A formula $\phi$ is valid (denoted $\models \phi$) if every possible truth assignment to its variables results in $\phi$ evaluating to true. This corresponds to the universal quantification over all possible models---the formula must hold in every conceivable scenario.

\subsection{Logical Consequence Problems}

The logical consequence problem represents a generalization of validity, asking whether a conclusion necessarily follows from given premises. Given a set of assumptions $\Gamma = \{\phi_1, \phi_2, \dots, \phi_n\}$ and a conjecture $\psi$, we determine if $\Gamma \models \psi$ (i.e., if $\psi$ is true in every model where all formulas in $\Gamma$ are true). This captures the essence of logical deduction---what conclusions are forced by the given information.

These three problems form the foundation of automated reasoning systems, with satisfiability serving as the most tractable and finding widespread application in practical problem-solving contexts. 


\section{Formal Language and Semantics}

\subsection{Logical Language: First-Order Logic}

The formal language employed in automated reasoning is first-order logic (FOL), a substantial extension of propositional logic that incorporates quantification over individual elements. First-order logic achieves greater expressive power by introducing:

\begin{itemize}
    \item \textbf{Individual variables} ranging over domain elements
    \item \textbf{Function symbols} for constructing complex terms
    \item \textbf{Predicate symbols} for expressing relations between elements
    \item \textbf{Quantifiers} ($\forall$, $\exists$) enabling statements about all or some elements
\end{itemize}

This enhanced expressiveness allows first-order logic to formalize mathematical structures, relationships, and properties in a manner impossible in propositional logic, which can only express truth-functional combinations of atomic propositions.

\subsection{Signature and Universe of Discourse}

A signature $\Sigma$ provides the vocabulary for interpreting formulas within a specific domain. Formally, a signature is a triple $\Sigma = \langle S, \mathcal{F}, \mathcal{P} \rangle$ where:

\begin{itemize}
    \item $S$ is a set of sorts (disjoint domains of interpretation)
    \item $\mathcal{F}$ is a set of function symbols, each with an arity specifying the number of arguments
    \item $\mathcal{P}$ is a set of predicate symbols, which we use to write formulas, each with an associated arity
\end{itemize}

The signature defines the syntactic elements available for constructing formulas, while the universe of discourse (or domain) provides the semantic interpretation. Sorts correspond to types in programming languages, enabling the formal specification of heterogeneous domains with different categories of objects.

The signature $\Sigma = \langle S, \mathcal{F}, \mathcal{P} \rangle$ can be further decomposed to provide a complete syntactic framework. The set of function symbols $\mathcal{F}$ is typically partitioned into two distinct subsets:

\begin{itemize}
    \item \textbf{Constant symbols} $C \subseteq \mathcal{F}$: These are function symbols of arity 0, representing named individuals in the domain. Constants have fixed interpretations and serve as proper names for specific domain elements.

    \item \textbf{Proper function symbols} $\mathcal{F} \setminus C$: These represent actual functions mapping tuples of domain elements to domain elements, each with arity $n \geq 1$.
\end{itemize}

Formally, a function symbol $f \in \mathcal{F}$ has type $s_1 \times s_2 \times \cdots \times s_n \rightarrow s$, where $s_1, \dots, s_n, s \in S$ are sorts indicating the domain and codomain of the function. For example:
\begin{itemize}
    \item $c : \rightarrow \texttt{int}$ (a constant symbol denoting a specific integer)
    \item $p : \rightarrow \texttt{color}$ (a constant symbol denoting a specific color)
    \item $f : \texttt{int} \times \texttt{int} \rightarrow \texttt{int}$ (a binary function like addition)
\end{itemize}

This decomposition enables precise specification of both individual elements (via constants) and functional relationships (via proper function symbols) within the formal language.

The complete signature structure $\langle S, C \cup (\mathcal{F} \setminus C) \cup \mathcal{P} \rangle$ provides the full syntactic foundation for expressing complex logical statements about structured domains.

Constants can be viewed as function symbols of arity 0---functions that require no arguments and directly denote specific domain elements. Additionally, to construct quantified formulas and express generality, we require a countably infinite set of variables $X = \{x, y, z, \dots\}$ disjoint from the signature symbols. 


Thus, the function symbols may be comprehensively categorized as $\mathcal{F} = C \cup (\mathcal{F} \setminus C) \cup \mathcal{P}$, where $\mathcal{P}$ represents the set of predicate symbols. Each predicate symbol $p \in \mathcal{P}$ has arity $n \geq 0$ and type $s_1 \times s_2 \times \cdots \times s_n$, where the final sort represents the truth value (typically a boolean sort).

Predicate symbols differ fundamentally from function symbols in that they represent relations rather than functions---they evaluate to truth values rather than domain elements. For example:
\begin{itemize}
    \item $even : \texttt{int} \rightarrow \texttt{bool}$ (unary predicate testing parity)
    \item $less : \texttt{int} \times \texttt{int} \rightarrow \texttt{bool}$ (binary relation for ordering)
\end{itemize}

The complete signature structure $\langle S, C \cup (\mathcal{F} \setminus C) \cup \mathcal{P} \rangle$ provides the full syntactic foundation for expressing complex logical statements about structured domains.

Constants can be viewed as function symbols of arity 0---functions that require no arguments and directly denote specific domain elements. Additionally, to construct quantified formulas and express generality, we require a countably infinite set of variables $X = \{x, y, z, \dots\}$ disjoint from the signature symbols.

\section{Syntactic Foundations: Terms and Formulas}

\subsection{Terms: The Building Blocks}

The most fundamental syntactic objects in first-order logic are \textbf{terms}, which represent individuals in the domain of discourse. The set of terms $\mathcal{T}_\Sigma(X)$ over signature $\Sigma$ and variables $X$ is inductively defined as the smallest set satisfying:

\begin{itemize}
    \item \textbf{Constants}: If $c \in C$ is a constant symbol, then $c \in \mathcal{T}_\Sigma(X)$
    \item \textbf{Variables}: If $x \in X$ is a variable, then $x \in \mathcal{T}_\Sigma(X)$
    \item \textbf{Function application}: If $f \in \mathcal{F}$ is a function symbol of arity $n \geq 1$ and $t_1, \dots, t_n \in \mathcal{T}_\Sigma(X)$ are terms, then $f(t_1, \dots, t_n) \in \mathcal{T}_\Sigma(X)$
\end{itemize}

Terms can be conceptualized as finite trees where:
\begin{itemize}
    \item Leaf nodes are constants or variables
    \item Internal nodes are function symbols applied to subterms
\end{itemize}

For example, the term $f(x, g(a), z)$ has the tree representation:
\[
\begin{array}{c}
  f \\
  | \\
  \begin{array}{ccc}
    x & g & z \\
       & | & \\
       & a &
  \end{array}
\end{array}
\]


Terms may contain subterms, which correspond to subtrees in this representation. Complex terms are constructed recursively from simpler subterms, reflecting the hierarchical nature of the syntactic structure.

\subsection{From Terms to Atomic Formulas}

Having established the notion of terms as representations of individuals, we now introduce atomic formulas to express relationships between these individuals. An \textbf{atomic formula} (or \textbf{atom}) is constructed by applying a predicate symbol to an appropriate number of terms.

Formally, if $P \in \mathcal{P}$ is a predicate symbol of arity $n \geq 0$ and $t_1, \dots, t_n \in \mathcal{T}_\Sigma(X)$ are terms, then $P(t_1, \dots, t_n)$ is an atomic formula. When $n = 0$, the atomic formula reduces to the predicate symbol itself $P$, which can be interpreted as a propositional constant.

The truth value of an atomic formula $P(t_1, \dots, t_n)$ depends on the interpretation of the predicate $P$ and the denotations of the terms $t_1, \dots, t_n$ in a given model.

\subsection{Literals: Positive and Negative Atomic Formulas}

A \textbf{literal} is either an atomic formula (positive literal) or its negation (negative literal). Formally, if $\phi$ is an atomic formula, then:
\begin{itemize}
    \item $\phi$ is a positive literal
    \item $\neg \phi$ is a negative literal
\end{itemize}

Literals represent the basic building blocks for constructing more complex logical formulas and play a crucial role in automated reasoning systems, particularly in resolution-based theorem proving.

\subsection{Logical Connectives}

Logical connectives provide the means to construct complex formulas from simpler ones. These operators enable the expression of compound logical statements through systematic combination of atomic formulas and literals.

The primary logical connectives include:
\begin{itemize}
    \item \textbf{Negation} ($\neg$): Expresses logical denial or contradiction
    \item \textbf{Conjunction} ($\wedge$): Represents logical conjunction (AND)
    \item \textbf{Disjunction} ($\vee$): Represents logical disjunction (OR)
    \item \textbf{Implication} ($\rightarrow$): Expresses logical implication (IF...THEN)
    \item \textbf{Biconditional} ($\leftrightarrow$): Represents logical equivalence (IF AND ONLY IF)
\end{itemize}

\subsection{Formulas: The Complete Syntax}

The set of \textbf{formulas} (or \textbf{well-formed formulas}) $\mathcal{F}_\Sigma(X)$ over signature $\Sigma$ and variables $X$ is inductively defined as the smallest set satisfying:

\begin{itemize}
    \item \textbf{Atomic formulas}: If $P \in \mathcal{P}$ is a predicate symbol of arity $n \geq 0$ and $t_1, \dots, t_n \in \mathcal{T}_\Sigma(X)$, then $P(t_1, \dots, t_n) \in \mathcal{F}_\Sigma(X)$

    \item \textbf{Negation}: If $\phi \in \mathcal{F}_\Sigma(X)$, then $(\neg \phi) \in \mathcal{F}_\Sigma(X)$

    \item \textbf{Binary connectives}: If $\phi, \psi \in \mathcal{F}_\Sigma(X)$, then:
        \begin{itemize}
            \item $(\phi \wedge \psi) \in \mathcal{F}_\Sigma(X)$ (conjunction)
            \item $(\phi \vee \psi) \in \mathcal{F}_\Sigma(X)$ (disjunction)
            \item $(\phi \rightarrow \psi) \in \mathcal{F}_\Sigma(X)$ (implication)
            \item $(\phi \leftrightarrow \psi) \in \mathcal{F}_\Sigma(X)$ (biconditional)
        \end{itemize}
\end{itemize}


This inductive definition ensures that all syntactically valid logical expressions can be systematically constructed from the basic building blocks of atomic formulas through the application of logical connectives.

\subsection{Quantifiers: Universality and Existence}

To complete the syntax of first-order logic, we introduce quantifiers that express generality and existence over the domain of discourse:

\begin{itemize}
    \item \textbf{Universal quantifier} ($\forall$): If $\phi \in \mathcal{F}_\Sigma(X)$ is a formula and $x \in X$ is a variable, then $(\forall x \, \phi) \in \mathcal{F}_\Sigma(X)$
    \item \textbf{Existential quantifier} ($\exists$): If $\phi \in \mathcal{F}_\Sigma(X)$ is a formula and $x \in X$ is a variable, then $(\exists x \, \phi) \in \mathcal{F}_\Sigma(X)$
\end{itemize}

Quantifiers bind variables within their scope, enabling the expression of properties that hold for all elements of the domain (universal quantification) or for at least one element (existential quantification).

\subsection{Illustrative Example: Geometric Axioms}

Consider the following first-order formula expressing that any two distinct points determine a unique line:

\[
\forall x \, \forall y \, \left( (P(x) \wedge P(y) \wedge x \neq y) \rightarrow \exists z \, (L(z) \wedge Q(z, x, y) \wedge \forall w \, (L(w) \wedge Q(w, x, y) \rightarrow w = z)) \right)
\]

Where:
\begin{itemize}
    \item $P(x)$ denotes that $x$ is a point
    \item $L(z)$ denotes that $z$ is a line
    \item $Q(z, x, y)$ denotes that line $z$ passes through points $x$ and $y$
    \item $x \neq y$ expresses that points $x$ and $y$ are distinct
\end{itemize}


This axiom formalizes the geometric principle that given any two distinct points in space, there exists exactly one line passing through both points, capturing a fundamental property of Euclidean geometry within the framework of first-order logic.

\subsection{Closed Formulas and Variable Scope}

A \textbf{closed formula} (or \textbf{sentence}) is a formula containing no free variables---all variables are bound by quantifiers. A variable is \textbf{free} in a formula if it appears outside the scope of any quantifier that binds it; conversely, a variable is \textbf{bound} if it appears within the scope of a quantifier.

Formulas may contain both free and bound occurrences of variables. For proper semantic interpretation, variables must be \textbf{standardized apart}, meaning that no variable appears both free and bound in the same formula, and distinct quantifiers use distinct bound variables.



\newpage

\part{Semantic Foundations}

\section{Interpretations and Models}

\subsection{The Concept of Interpretation}

To assign meaning to syntactic formulas in first-order logic, we require a formal notion of \textbf{interpretation}. An interpretation $\mathcal{I}$ provides a semantic mapping from the syntactic elements of a signature to concrete mathematical objects.

In the unsorted case, an interpretation consists of:
\begin{itemize}
    \item A non-empty set $D$ called the \textbf{domain} (or universe of discourse)
    \item An interpretation function $\Phi$ that maps:
    \begin{itemize}
        \item Each predicate symbol $P \in \mathcal{P}$ of arity $n$ to a subset $\Phi(P) \subseteq D^n$ (representing an $n$-ary relation over the domain)
        \item Each function symbol $f \in \mathcal{F}$ of arity $n$ to a function $\Phi(f) : D^n \rightarrow D$
        \item Each constant symbol $c \in C$ to a specific element $\Phi(c) \in D$
    \end{itemize}
\end{itemize}

The interpretation function $\Phi$ bridges the gap between syntax and semantics, transforming abstract symbols into concrete mathematical entities.

\subsection{Example: Interpreting a Formula over Natural Numbers}

Consider the first-order formula:
\[
\forall x \, (\neg P(x) \rightarrow P(f(x)))
\]

This formula contains:
\begin{itemize}
    \item A unary predicate symbol $P$
    \item A unary function symbol $f$
    \item A universally quantified variable $x$
\end{itemize}

Since the formula is closed (contains no free variables), its truth value depends entirely on the chosen interpretation.

\textbf{Constructing an interpretation}: Let us define an interpretation $\mathcal{I} = \langle D, \Phi \rangle$ where:
\begin{itemize}
    \item \textbf{Domain}: $D = \N$ (the set of natural numbers)
    \item \textbf{Function interpretation}: $\Phi(f) : \N \rightarrow \N$ is the successor function, defined by $\Phi(f)(n) = n + 1$ for all $n \in \N$
    \item \textbf{Predicate interpretation}: $\Phi(P) = \{0, 2, 4, 6, \dots\} = \{2k \mid k \in \N\}$ (the set of even natural numbers)
\end{itemize}

\subsection{Semantic Evaluation}

Under this interpretation $\mathcal{I}$, the formula $\forall x \, (\neg P(x) \rightarrow P(f(x)))$ receives the following semantic reading:

\textit{For all natural numbers $x$, if $x$ is not even, then the successor of $x$ is even.}

To determine whether this formula is true in interpretation $\mathcal{I}$, we must verify whether the implication holds for every element of the domain:
\begin{itemize}
    \item If $x$ is odd (i.e., $x \notin \Phi(P)$), then $x + 1$ must be even (i.e., $x + 1 \in \Phi(P)$)
\end{itemize}

This statement is indeed true in the natural numbers: the successor of any odd number is even. Therefore, the formula is \textbf{satisfied} by interpretation $\mathcal{I}$, and we write $\mathcal{I} \models \forall x \, (\neg P(x) \rightarrow P(f(x)))$.

\subsection{Formal Verification of Satisfaction}

To formally verify that $\mathcal{I} \models \forall x \, (\neg P(x) \rightarrow P(f(x)))$, we must check that for all $n \in \N$, the interpretation satisfies the implication with the substitution $\{x \leftarrow n\}$.

By the semantics of implication, $\mathcal{I}$ satisfies $(\neg P(x) \rightarrow P(f(x)))$ with assignment $\{x \leftarrow n\}$ if and only if:
\begin{itemize}
    \item Either $\mathcal{I}$ does not satisfy $\neg P(x)$ with $\{x \leftarrow n\}$ (i.e., $\mathcal{I}$ satisfies $P(x)$ with $\{x \leftarrow n\}$), or
    \item $\mathcal{I}$ satisfies $P(f(x))$ with $\{x \leftarrow n\}$
\end{itemize}

Equivalently, for all $n \in \N$, either $n \in \Phi(P)$ or $\Phi(f)(n) \in \Phi(P)$.

\textbf{Truth condition for atomic formulas}: An atomic formula $P(t)$ is true under interpretation $\mathcal{I}$ if and only if the interpretation of the term $t$ belongs to the interpretation of the predicate $\Phi(P)$.

In our example, for all $n \in \N$:
\begin{itemize}
    \item Either $n \in \Phi(P)$ (meaning $n$ is even), or
    \item $\Phi(f)(n) = n + 1 \in \Phi(P)$ (meaning the successor of $n$ is even)
\end{itemize}

This condition holds for all natural numbers, confirming that the formula is satisfied by the interpretation.

\subsection{Formal Definition of Interpretation}

Having illustrated the concept through examples, we now provide the complete formal definition of an interpretation in first-order logic.

An \textbf{interpretation} $\mathcal{I}$ consists of a triple $\mathcal{I} = \langle D, \Phi, \beta \rangle$ where:

\begin{itemize}
    \item \textbf{Domain}: $D$ is a non-empty set representing the universe of discourse
    
    \item \textbf{Interpretation function} $\Phi$ maps signature symbols to semantic objects:
    \begin{itemize}
        \item For each constant symbol $c \in C$: $\Phi(c) = d \in D$
        \item For each function symbol $f \in \mathcal{F}$ of arity $n \geq 1$: $\Phi(f) : D^n \rightarrow D$, where $D^n$ denotes the $n$-fold Cartesian product $D \times D \times \cdots \times D$
        \item For each predicate symbol $P \in \mathcal{P}$ of arity $n \geq 0$: $\Phi(P) \subseteq D^n$ (an $n$-ary relation over $D$)
    \end{itemize}
    
    \item \textbf{Variable assignment} $\beta$ maps each variable to a domain element:
    \begin{itemize}
        \item $\beta : X \rightarrow D$ such that $\beta(x) = d \in D$ for all variables $x \in X$
    \end{itemize}
\end{itemize}

\textbf{Assignment update notation}: Given an assignment $\beta$ and a substitution $x \leftarrow d$, we define the updated assignment $\beta[x \leftarrow d]$ as:
\[
\beta[x \leftarrow d](y) = 
\begin{cases}
d & \text{if } y = x \\
\beta(y) & \text{otherwise}
\end{cases}
\]

This notation allows us to formally express the evaluation of formulas with different variable bindings, which is essential for defining the semantics of quantified formulas.






\section{Satisfaction Relation}

\subsection{The Satisfaction Relation}

Having defined interpretations and variable assignments, we now formalize the central semantic concept: when does an interpretation \textbf{satisfy} a formula? The satisfaction relation, denoted $\mathcal{I} \models_\beta \phi$, specifies the conditions under which a formula $\phi$ is true in interpretation $\mathcal{I}$ with variable assignment $\beta$.

Let $F$ and $G$ denote arbitrary formulas. The satisfaction relation is defined inductively on the structure of formulas.

\subsection{Interpretation of Terms}

Before defining satisfaction for formulas, we must specify how terms are interpreted. Given an interpretation $\mathcal{I} = \langle D, \Phi, \beta \rangle$, the interpretation of a term $t$, denoted $\Phi_\beta(t)$, is defined recursively:

\begin{itemize}
    \item \textbf{Constants}: $\Phi_\beta(c) = \Phi(c) \in D$
    \item \textbf{Variables}: $\Phi_\beta(x) = \beta(x) \in D$
    \item \textbf{Function application}: $\Phi_\beta(f(t_1, \dots, t_n)) = \Phi(f)(\Phi_\beta(t_1), \dots, \Phi_\beta(t_n)) \in D$
\end{itemize}

Each term evaluates to a specific element of the domain under a given interpretation.

\subsection{Satisfaction for Atomic Formulas}

\textbf{Base case} (atomic formulas): An interpretation $\mathcal{I}$ satisfies an atomic formula $P(t_1, \dots, t_n)$ under assignment $\beta$ if and only if the tuple of interpreted terms belongs to the interpretation of the predicate:

\[
\mathcal{I} \models_\beta P(t_1, \dots, t_n) \quad \text{iff} \quad (\Phi_\beta(t_1), \dots, \Phi_\beta(t_n)) \in \Phi(P)
\]

\subsection{Satisfaction for Logical Connectives}

The satisfaction relation extends to compound formulas through the following inductive clauses. Note that all satisfaction relations are parameterized by the variable assignment $\beta$, written as $\models_\beta$.

\begin{itemize}
    \item \textbf{Negation}: 
    \[
    \mathcal{I} \models_\beta \neg F \quad \text{iff} \quad \mathcal{I} \not\models_\beta F
    \]
    
    \item \textbf{Conjunction}: 
    \[
    \mathcal{I} \models_\beta (F \wedge G) \quad \text{iff} \quad \mathcal{I} \models_\beta F \text{ and } \mathcal{I} \models_\beta G
    \]
    
    \item \textbf{Disjunction}: 
    \[
    \mathcal{I} \models_\beta (F \vee G) \quad \text{iff} \quad \mathcal{I} \models_\beta F \text{ or } \mathcal{I} \models_\beta G
    \]
    
    \item \textbf{Implication}: 
    \[
    \mathcal{I} \models_\beta (F \rightarrow G) \quad \text{iff} \quad \mathcal{I} \not\models_\beta F \text{ or } \mathcal{I} \models_\beta G
    \]
    Equivalently: if $\mathcal{I} \models_\beta F$ then $\mathcal{I} \models_\beta G$
    
    \item \textbf{Biconditional}: 
    \[
    \mathcal{I} \models_\beta (F \leftrightarrow G) \quad \text{iff} \quad \mathcal{I} \models_\beta F \text{ if and only if } \mathcal{I} \models_\beta G
    \]
\end{itemize}

\subsection{Satisfaction for Quantified Formulas}

Quantifiers introduce variable bindings that range over the entire domain:

\begin{itemize}
    \item \textbf{Universal quantification}: 
    \[
    \mathcal{I} \models_\beta \forall x \, G \quad \text{iff} \quad \text{for all } d \in D, \, \mathcal{I} \models_{\beta[x \leftarrow d]} G
    \]
    The formula $\forall x \, G$ is satisfied if $G$ is satisfied under every possible assignment to $x$.
    
    \item \textbf{Existential quantification}: 
    \[
    \mathcal{I} \models_\beta \exists x \, G \quad \text{iff} \quad \text{there exists } d \in D \text{ such that } \mathcal{I} \models_{\beta[x \leftarrow d]} G
    \]
    The formula $\exists x \, G$ is satisfied if $G$ is satisfied under at least one assignment to $x$.
\end{itemize}

This completes the inductive definition of the satisfaction relation, providing a complete semantics for first-order logic.

\subsection{Example: Quantifier Evaluation}

Consider the formula $\forall x \, \exists y \, R(x, y)$, which can be read as "for all $x$, there exists $y$ such that $x < y$".

Let $\mathcal{I} = \langle \N, \Phi \rangle$ where $\Phi(R) = \{(n, m) \in \N \times \N \mid n < m\}$ (the standard ordering on natural numbers).

To verify $\mathcal{I} \models \forall x \, \exists y \, R(x, y)$, we apply the semantic definitions:
\begin{align*}
\mathcal{I} \models \forall x \, \exists y \, R(x, y) 
&\quad \text{iff} \quad \text{for all } n \in \N, \, \mathcal{I} \models_{\beta[x \leftarrow n]} \exists y \, R(x, y) \\
&\quad \text{iff} \quad \text{for all } n \in \N, \text{ there exists } m \in \N \text{ such that } \mathcal{I} \models_{\beta[x \leftarrow n, y \leftarrow m]} R(x, y) \\
&\quad \text{iff} \quad \text{for all } n \in \N, \text{ there exists } m \in \N \text{ such that } (n, m) \in \Phi(R) \\
&\quad \text{iff} \quad \text{for all } n \in \N, \text{ there exists } m \in \N \text{ such that } n < m
\end{align*}

This statement is \textbf{false} in $\N$ because there is no natural number greater than all natural numbers. However, it would be true in $\mathbb{Z}$ or $\mathbb{Q}$, demonstrating how truth depends on the chosen interpretation.

\section{Semantic Properties of Formulas}

Having established the satisfaction relation, we now define fundamental semantic properties that classify formulas according to their truth behavior across different interpretations.

\subsection{Satisfiability}

A formula $F$ is \textbf{satisfiable} if there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models F$. In this case, we say that $\mathcal{I}$ is a \textbf{model} of $F$.

\[
F \text{ is satisfiable} \quad \Leftrightarrow \quad \exists \mathcal{I} : \mathcal{I} \models F
\]

\subsection{Validity}

A formula $F$ is \textbf{valid} (or a \textbf{tautology}) if for all interpretations $\mathcal{I}$, we have $\mathcal{I} \models F$. Valid formulas are true in every possible interpretation.

\[
F \text{ is valid} \quad \Leftrightarrow \quad \forall \mathcal{I} : \mathcal{I} \models F
\]

We denote validity by $\models F$.

\subsection{Unsatisfiability}

A formula $F$ is \textbf{unsatisfiable} (or \textbf{contradictory}) if there exists no interpretation $\mathcal{I}$ such that $\mathcal{I} \models F$. Unsatisfiable formulas are false in every interpretation.

\[
F \text{ is unsatisfiable} \quad \Leftrightarrow \quad \nexists \mathcal{I} : \mathcal{I} \models F \quad \Leftrightarrow \quad \forall \mathcal{I} : \mathcal{I} \not\models F
\]

\subsection{Invalidity}

A formula $F$ is \textbf{invalid} (or \textbf{falsifiable}) if there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \not\models F$. In this case, we say that $\mathcal{I}$ is a \textbf{countermodel} (or \textbf{counterexample}) for $F$.

\[
F \text{ is invalid} \quad \Leftrightarrow \quad \exists \mathcal{I} : \mathcal{I} \not\models F
\]

\subsection{Relationships Between Semantic Properties}

These semantic properties are intimately related through negation:

\begin{theorem}[Validity and Unsatisfiability]
A formula $F$ is valid if and only if $\neg F$ is unsatisfiable.
\end{theorem}

\begin{proof}
Suppose $F$ is valid. Then for all interpretations $\mathcal{I}$, we have $\mathcal{I} \models F$, which implies $\mathcal{I} \not\models \neg F$. Therefore, $\neg F$ is unsatisfiable.

Conversely, if $\neg F$ is unsatisfiable, then for all interpretations $\mathcal{I}$, we have $\mathcal{I} \not\models \neg F$, which implies $\mathcal{I} \models F$. Therefore, $F$ is valid.
\end{proof}

\begin{theorem}[Satisfiability and Invalidity]
A formula $F$ is satisfiable if and only if $\neg F$ is invalid.
\end{theorem}

\begin{proof}
$F$ is satisfiable if and only if there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models F$, which is equivalent to $\mathcal{I} \not\models \neg F$. This is precisely the condition for $\neg F$ to be invalid.
\end{proof}

These relationships demonstrate the duality between validity and unsatisfiability, and between satisfiability and invalidity, providing a complete characterization of the semantic landscape of first-order logic.

\section{Logical Consequence}

\subsection{The Three Fundamental Query Types}

Automated reasoning systems must be capable of resolving three fundamental types of semantic queries:
\begin{enumerate}
    \item \textbf{Satisfiability queries}: Is formula $F$ satisfiable?
    \item \textbf{Validity queries}: Is formula $F$ valid?
    \item \textbf{Logical consequence queries}: Does $F$ follow logically from a set of hypotheses $H$?
\end{enumerate}

\subsection{Definition of Logical Consequence}

Let $H = \{\phi_1, \phi_2, \dots, \phi_n\}$ be a set of formulas (the \textbf{hypotheses} or \textbf{premises}) and let $F$ be a formula (the \textbf{conclusion}). We say that $F$ is a \textbf{logical consequence} of $H$, written $H \models F$, and read as "$H$ entails $F$" or "$F$ follows logically from $H$", if:

\[
H \models F \quad \Leftrightarrow \quad \text{for all interpretations } \mathcal{I}, \text{ if } \mathcal{I} \models H \text{ then } \mathcal{I} \models F
\]

In other words, $F$ is a logical consequence of $H$ if every model of $H$ is also a model of $F$. Here, $\mathcal{I} \models H$ means that $\mathcal{I}$ satisfies all formulas in $H$.

\subsection{The Deduction Theorem}

The deduction theorem establishes a fundamental connection between logical consequence and validity, reducing the problem of checking entailment to the problem of checking validity.

\begin{theorem}[Deduction Theorem]
Let $H$ be a set of formulas and $F$ be a formula. Then:
\[
H \models F \quad \text{iff} \quad \models (H \rightarrow F)
\]
where $H \rightarrow F$ denotes the implication from the conjunction of all formulas in $H$ to $F$.
\end{theorem}

\begin{proof}
We prove both directions:

\textbf{($\Rightarrow$)} Assume $H \models F$. We must show that $H \rightarrow F$ is valid, i.e., for all interpretations $\mathcal{I}$, we have $\mathcal{I} \models H \rightarrow F$.

Let $\mathcal{I}$ be an arbitrary interpretation. By the semantics of implication, $\mathcal{I} \models H \rightarrow F$ holds if either:
\begin{itemize}
    \item $\mathcal{I} \not\models H$ (the antecedent is false), or
    \item $\mathcal{I} \models F$ (the consequent is true)
\end{itemize}

If $\mathcal{I} \not\models H$, then $\mathcal{I} \models H \rightarrow F$ trivially. If $\mathcal{I} \models H$, then by the hypothesis $H \models F$, we have $\mathcal{I} \models F$, so $\mathcal{I} \models H \rightarrow F$. In both cases, $\mathcal{I} \models H \rightarrow F$.

\textbf{($\Leftarrow$)} Conversely, suppose $H \rightarrow F$ is valid. Then for all interpretations $\mathcal{I}$, we have $\mathcal{I} \models H \rightarrow F$. By the semantics of implication, for all $\mathcal{I}$, either $\mathcal{I} \not\models H$ or $\mathcal{I} \models F$. Therefore, for all $\mathcal{I}$ such that $\mathcal{I} \models H$, we must have $\mathcal{I} \models F$, which is precisely the definition of $H \models F$.
\end{proof}

\subsection{Notational Ambiguity of $\models$}

The symbol $\models$ is used in three distinct but related contexts:

\begin{itemize}
    \item \textbf{Satisfaction}: $\mathcal{I} \models F$ means interpretation $\mathcal{I}$ satisfies formula $F$
    \item \textbf{Validity}: $\models F$ means formula $F$ is valid (satisfied by all interpretations)
    \item \textbf{Entailment}: $H \models F$ means formula $F$ is a logical consequence of the set of formulas $H$
\end{itemize}

While this overloading may initially seem confusing, these three uses are semantically coherent and represent different aspects of the same fundamental semantic relation.

\subsection{Reduction to Unsatisfiability}

A fundamental result connects logical consequence to unsatisfiability, providing another characterization of entailment.

\begin{theorem}[Logical Consequence via Unsatisfiability]
Let $H$ be a set of formulas and $F$ be a formula. Then:
\[
H \models F \quad \text{iff} \quad H \cup \{\neg F\} \text{ is unsatisfiable}
\]
\end{theorem}

\begin{proof}
We prove both directions:

\textbf{($\Rightarrow$)} Assume $H \models F$. We must show that $H \cup \{\neg F\}$ is unsatisfiable.

Suppose for contradiction that there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models H \cup \{\neg F\}$. Then $\mathcal{I} \models H$ and $\mathcal{I} \models \neg F$, which implies $\mathcal{I} \not\models F$. However, since $H \models F$ and $\mathcal{I} \models H$, we must have $\mathcal{I} \models F$, which is a contradiction. Therefore, $H \cup \{\neg F\}$ is unsatisfiable.

\textbf{($\Leftarrow$)} Assume $H \cup \{\neg F\}$ is unsatisfiable. We must show that $H \models F$.

Let $\mathcal{I}$ be any interpretation such that $\mathcal{I} \models H$. Since $H \cup \{\neg F\}$ is unsatisfiable, there is no interpretation that satisfies both $H$ and $\neg F$. Therefore, $\mathcal{I} \not\models \neg F$, which implies $\mathcal{I} \models F$. Since this holds for all interpretations satisfying $H$, we conclude that $H \models F$.
\end{proof}

\section{Refutational Reasoning}

\subsection{Proof by Contradiction}

\textbf{Refutational reasoning} (or \textbf{proof by refutation}) is a fundamental technique in automated reasoning based on the principle of \textit{reductio ad absurdum}. To prove that a conclusion $F$ follows from hypotheses $H$, we assume the negation of the conclusion and derive a contradiction.

The method proceeds as follows:
\begin{enumerate}
    \item \textbf{Goal}: Prove $H \models F$ (where $H$ represents assumptions and $F$ represents the conjecture)
    \item \textbf{Method}: Show that $H \cup \{\neg F\}$ is unsatisfiable
    \item \textbf{Conclusion}: If $H \cup \{\neg F\}$ is unsatisfiable, then $H \models F$ by the previous theorem
\end{enumerate}

\subsection{The Refutational Framework}

The automated reasoning process can be formalized as follows:

\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (input) {$H \cup \{\neg F\}$};
    \node (procedure) [rectangle, draw, right of=input, node distance=4cm] {Decision Procedure};
    \node (unsat) [below right of=procedure, node distance=3cm] {\textbf{Unsatisfiable}};
    \node (sat) [above right of=procedure, node distance=3cm] {\textbf{Satisfiable}};
    
    \draw[->] (input) -- (procedure);
    \draw[->] (procedure) -- node[near start, above] {Yes} (unsat);
    \draw[->] (procedure) -- node[near start, above] {No} (sat);
    
    \node[right of=unsat, node distance=3.5cm, text width=3.5cm] {Proof found (refutation): $H \models F$};
    \node[right of=sat, node distance=3.5cm, text width=3.5cm] {Model found: counterexample to $H \models F$};
\end{tikzpicture}
\end{center}

\textbf{Two possible outcomes}:
\begin{itemize}
    \item \textbf{Unsatisfiable}: The procedure derives a contradiction, producing a \textbf{refutation} (proof) that $H \models F$
    \item \textbf{Satisfiable}: The procedure finds a model $\mathcal{I}$ of $H \cup \{\neg F\}$, which serves as a \textbf{counterexample} showing that $H \not\models F$
\end{itemize}

This refutational approach forms the foundation of modern automated theorem provers and SAT solvers, reducing the problem of proving logical consequence to the problem of detecting unsatisfiability.




\newpage

\part{Free Variables and Satisfiability}

\section{Satisfiability of Formulas with Free Variables}

\subsection{The Problem of Free Variables}

In our previous definition of satisfiability, we considered the semantics of logical connectives and quantifiers, but we did not fully address the treatment of \textbf{free variables}. Recall that a variable can be either:
\begin{itemize}
    \item \textbf{Bound}: The variable falls within the scope of a quantifier
    \item \textbf{Free}: The variable does not fall within the scope of any quantifier
\end{itemize}

The presence of free variables requires careful consideration when determining satisfiability, as their interpretation depends on the variable assignment $\beta$.

\subsection{Motivating Example}

Consider the following formula:
\[
F: \forall x \, (f(x, x) = x \wedge R(x, y))
\]

This formula contains:
\begin{itemize}
    \item A bound variable $x$ (quantified by $\forall$)
    \item A free variable $y$ (not quantified)
\end{itemize}

\subsection{Semantic Evaluation with Free Variables}

To determine whether an interpretation $\mathcal{I} = \langle D, \Phi \rangle$ with assignment $\beta$ satisfies $F$, we write $\mathcal{I} \models_\beta F$ and proceed as follows:

By the semantics of universal quantification, we need to check that for all $d \in D$:
\[
\mathcal{I} \models_{\beta[x \leftarrow d]} (f(x, x) = x \wedge R(x, y))
\]

This requires verifying both conjuncts under the updated assignment $\beta[x \leftarrow d]$:

\textbf{First conjunct}: $\mathcal{I} \models_{\beta[x \leftarrow d]} f(x, x) = x$

This holds if and only if:
\[
(\Phi(f)(d, d), d) \in \Phi(=)
\]
where $\Phi(=)$ represents the identity relation. In other words, we require that $\Phi(f)(d, d) = d$ for all $d \in D$.

\textbf{Second conjunct}: $\mathcal{I} \models_{\beta[x \leftarrow d]} R(x, y)$

This holds if and only if:
\[
(d, \beta(y)) \in \Phi(R)
\]

Let $\beta(y) = d'$ for some $d' \in D$. Then we require $(d, d') \in \Phi(R)$ for all $d \in D$.

\subsection{Existential Closure}

The key observation is that the satisfiability of a formula with free variables is intimately connected to its \textbf{existential closure}.

\begin{definition}[Existential Closure]
The existential closure of a formula $F$, denoted $\exists^* F$, is obtained by adding an existential quantifier for every free variable in $F$.
\end{definition}

For example, if $F$ contains free variables $y_1, y_2, \dots, y_n$, then:
\[
\exists^* F = \exists y_1 \, \exists y_2 \, \cdots \, \exists y_n \, F
\]

Returning to our example, if we consider the existential closure by quantifying the free variable $y$:
\[
\exists y \, \forall x \, (f(x, x) = x \wedge R(x, y))
\]

Under this interpretation, we need to verify that there exists some $d' \in D$ such that for all $d \in D$:
\[
\mathcal{I} \models_{\beta[x \leftarrow d, y \leftarrow d']} R(x, y)
\]
which means $(d, d') \in \Phi(R)$ for all $d \in D$.

\subsection{Satisfiability for Open Formulas}

We now provide the complete definition of satisfiability that handles both closed and open formulas.

\begin{definition}[Satisfiability - Complete Definition]
A formula $F$ is \textbf{satisfiable} if:
\begin{itemize}
    \item \textbf{Case 1 (Closed formula)}: If $F$ is a sentence (contains no free variables), then $F$ is satisfiable if there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models F$.
    
    \item \textbf{Case 2 (Open formula)}: If $F$ contains free variables, then $F$ is satisfiable if there exists an interpretation $\mathcal{I}$ and a variable assignment $\beta$ such that $\mathcal{I} \models_\beta F$.
\end{itemize}
\end{definition}

\begin{theorem}[Satisfiability and Existential Closure]
A formula $F$ with free variables is satisfiable if and only if its existential closure $\exists^* F$ is satisfiable.
\end{theorem}

\begin{proof}
Let $F$ be a formula with free variables $y_1, \dots, y_n$, and let $\exists^* F = \exists y_1 \, \cdots \, \exists y_n \, F$.

\textbf{($\Rightarrow$)} Suppose $F$ is satisfiable. Then there exists an interpretation $\mathcal{I}$ and assignment $\beta$ such that $\mathcal{I} \models_\beta F$. Let $d_i = \beta(y_i)$ for $i = 1, \dots, n$. Then by the semantics of existential quantification applied repeatedly, $\mathcal{I} \models \exists^* F$.

\textbf{($\Leftarrow$)} Suppose $\exists^* F$ is satisfiable. Then there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models \exists y_1 \, \cdots \, \exists y_n \, F$. By the semantics of existential quantification, there exist $d_1, \dots, d_n \in D$ such that $\mathcal{I} \models_{\beta[y_1 \leftarrow d_1, \dots, y_n \leftarrow d_n]} F$. Therefore, $F$ is satisfiable.
\end{proof}

This result demonstrates that when checking satisfiability of formulas with free variables, we can equivalently check the satisfiability of their existential closures, treating free variables as existentially quantified.

\subsection{Universal Closure and Validity}

Dually, we can consider the \textbf{universal closure} of a formula with free variables.

\begin{theorem}[Validity and Universal Closure]
A formula $F$ with free variables is valid if and only if its universal closure $\forall^* F$ is valid.
\end{theorem}

The intuition is straightforward: if $F$ contains free variables, then $F$ is valid if for all interpretations $\mathcal{I}$ and for all assignments $\beta$, we have $\mathcal{I} \models_\beta F$. This is precisely the condition for the universal closure $\forall^* F$ to be valid.

\newpage

\section{Decidability and Semidecidability in First-Order Logic}

\subsection{Computational Complexity of First-Order Logic}

While certain restricted fragments of first-order logic admit decision procedures, the general case presents fundamental computational limitations:

\begin{itemize}
    \item \textbf{Unsatisfiability} in first-order logic is \textbf{semidecidable} (recursively enumerable)
    \item \textbf{Satisfiability} in first-order logic is \textbf{not even semidecidable}
\end{itemize}

\begin{remark}
Recall that if a decision problem $A$ is semidecidable and its complement $\neg A$ is also semidecidable, then $A$ is decidable. The decision procedure can be obtained by running both semidecision procedures in parallel: if the instance belongs to $A$, the first procedure will eventually terminate with "yes"; if the instance belongs to $\neg A$, the second procedure will eventually terminate with "yes".
\end{remark}

\subsection{Review: Semi-Decision Procedures}

Consider the problem of determining whether $H \models F$ (logical consequence).

\textbf{Semi-decision procedure for unsatisfiability}:
\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (input) {$H \cup \{\neg F\}$};
    \node (procedure) [rectangle, draw, right of=input, node distance=4.5cm] {Semi-decision for UNSAT};
    \node (yes) [below of=procedure, node distance=2cm] {\textbf{Yes}: $H \cup \{\neg F\}$ is UNSAT};
    \node (unknown) [above of=procedure, node distance=2cm] {$?$ (may not terminate)};
    
    \draw[->] (input) -- (procedure);
    \draw[->] (procedure) -- (yes);
\end{tikzpicture}
\end{center}

If the procedure terminates with "yes", we have proven $H \models F$ by refutation. However, if $H \cup \{\neg F\}$ is satisfiable, the procedure may run indefinitely.

\textbf{Semi-decision procedure for satisfiability}:
\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (input) {$H \cup \{\neg F\}$};
    \node (procedure) [rectangle, draw, right of=input, node distance=4.5cm] {Semi-decision for SAT};
    \node (yes) [below of=procedure, node distance=2cm] {\textbf{Yes}: model found (counterexample to $H \models F$)};
    \node (unknown) [above of=procedure, node distance=2cm] {$?$ (may not terminate)};
    
    \draw[->] (input) -- (procedure);
    \draw[->] (procedure) -- (yes);
\end{tikzpicture}
\end{center}

If this procedure terminates with "yes", we have found a countermodel showing $H \not\models F$. However, such a procedure does not exist for general first-order logic.

\subsection{The Need for Restricted Theories}

To obtain decision procedures, we must restrict our attention to \textbf{decidable fragments} of first-order logic. This motivates the study of \textbf{first-order theories}---logical systems with additional structure that enable algorithmic reasoning.

\section{First-Order Theories}

\subsection{Definition of a First-Order Theory}

\begin{definition}[First-Order Theory]
A \textbf{first-order theory} is a pair $\mathcal{T} = \langle \Sigma, \mathcal{A} \rangle$ where:
\begin{itemize}
    \item $\Sigma$ is a \textbf{signature} (defining the vocabulary of the theory)
    \item $\mathcal{A}$ is a set of \textbf{axioms}---closed formulas (sentences) that we assume to hold in all models of the theory
\end{itemize}
\end{definition}

The axioms define properties of specific symbols in the signature, giving them fixed interpretations across all models of the theory.

\subsection{The Theory of Equality}

A fundamental example is the \textbf{theory of equality} $\mathcal{T}_E = \langle \Sigma_E, \mathcal{A}_E \rangle$.

\textbf{Signature}: The signature of the theory of equality is:
\[
\Sigma_E = \{=\} \cup C \cup \mathcal{F} \cup \mathcal{P}
\]
where:
\begin{itemize}
    \item $=$ is the equality predicate (interpreted symbol)
    \item $C$ is a set of constant symbols (uninterpreted)
    \item $\mathcal{F}$ is a set of function symbols (uninterpreted)
    \item $\mathcal{P}$ is a set of predicate symbols (uninterpreted)
\end{itemize}

\textbf{Example signature}: Consider $\Sigma = \{a, b, f, Q, =\}$. The symbols $a, b, f, Q$ are \textbf{free} (uninterpreted), whereas $=$ (equality) is \textbf{defined} by the axioms of the theory.

\subsection{Axioms of Equality}

The axiom set $\mathcal{A}_E$ consists of formulas that characterize equality as a congruence relation.

\textbf{Equivalence relation axioms}:
\begin{align*}
&\forall x \, (x = x) && \text{(Reflexivity)} \\
&\forall x \, \forall y \, (x = y \rightarrow y = x) && \text{(Symmetry)} \\
&\forall x \, \forall y \, \forall z \, ((x = y \wedge y = z) \rightarrow x = z) && \text{(Transitivity)}
\end{align*}

These three axioms establish that equality is an equivalence relation.

\textbf{Congruence axioms for function symbols}: For each function symbol $f \in \mathcal{F}$ of arity $n$:
\[
\forall \vec{x} \, \forall \vec{y} \, \left( \bigwedge_{i=1}^{n} x_i = y_i \right) \rightarrow f(x_1, \dots, x_n) = f(y_1, \dots, y_n)
\]
where $\vec{x} = (x_1, \dots, x_n)$ and $\vec{y} = (y_1, \dots, y_n)$.

This axiom states that $f$ respects equality: equal inputs produce equal outputs.

\textbf{Congruence axioms for predicate symbols}: For each predicate symbol $R \in \mathcal{P}$ of arity $n$:
\[
\forall \vec{x} \, \forall \vec{y} \, \left( \bigwedge_{i=1}^{n} x_i = y_i \right) \rightarrow (R(x_1, \dots, x_n) \leftrightarrow R(y_1, \dots, y_n))
\]

This axiom states that $R$ respects equality: the truth value of $R$ depends only on the equivalence classes of its arguments.

\subsection{Models of a Theory}

\begin{definition}[$\mathcal{T}$-Model]
A \textbf{$\mathcal{T}$-model} is an interpretation $\mathcal{I}$ such that $\mathcal{I} \models \mathcal{A}$ (i.e., $\mathcal{I}$ satisfies all axioms in $\mathcal{A}$).
\end{definition}

\subsection{Satisfiability and Validity Relative to a Theory}

\begin{definition}[$\mathcal{T}$-Satisfiability]
A formula $G$ is \textbf{$\mathcal{T}$-satisfiable} if there exists a $\mathcal{T}$-model $\mathcal{I}$ such that $\mathcal{I} \models G$.
\end{definition}

\begin{definition}[$\mathcal{T}$-Validity]
A formula $G$ is \textbf{$\mathcal{T}$-valid} if for all $\mathcal{T}$-models $\mathcal{I}$, we have $\mathcal{I} \models G$.

Equivalently, $G$ is a logical consequence of the axioms: $\mathcal{A} \models G$.
\end{definition}

\subsection{Example: Satisfiability vs. $\mathcal{T}_E$-Satisfiability}

Consider the set of formulas:
\[
S = \{ P(a), \neg P(b), a = b \}
\]

\textbf{Claim}: $S$ is satisfiable in general first-order logic, but $S$ is \textbf{not $\mathcal{T}_E$-satisfiable}.

\begin{proof}
\textbf{Satisfiability}: We can construct an interpretation $\mathcal{I}$ with domain $D = \{d_1, d_2\}$ where:
\begin{itemize}
    \item $\Phi(a) = d_1$, $\Phi(b) = d_2$
    \item $\Phi(P) = \{d_1\}$
    \item $\Phi(=) = \{(d_1, d_1), (d_2, d_2), (d_1, d_2), (d_2, d_1)\}$ (universal relation)
\end{itemize}
Then $\mathcal{I} \models P(a)$, $\mathcal{I} \models \neg P(b)$, and $\mathcal{I} \models a = b$, so $\mathcal{I} \models S$.

\textbf{$\mathcal{T}_E$-Unsatisfiability}: In any $\mathcal{T}_E$-model, equality must satisfy the congruence axioms. If $\mathcal{I} \models a = b$ and $\mathcal{I} \models P(a)$, then by the congruence axiom for $P$, we must have $\mathcal{I} \models P(b)$, contradicting $\mathcal{I} \models \neg P(b)$. Therefore, no $\mathcal{T}_E$-model satisfies $S$.
\end{proof}

This example illustrates that satisfiability relative to a theory is more restrictive than general satisfiability, as models must respect the additional constraints imposed by the theory's axioms.

\section{Quantifier-Free Fragments and Decidability}

\subsection{The Quantifier-Free Fragment of $\mathcal{T}_E$}

While the full theory of equality $\mathcal{T}_E$ is undecidable, its \textbf{quantifier-free fragment} admits a decision procedure.

\begin{definition}[Quantifier-Free Fragment]
The \textbf{quantifier-free fragment} of first-order logic consists of all formulas that do not contain quantifiers ($\forall$ or $\exists$).

For a theory $\mathcal{T}$, the quantifier-free fragment allows quantifiers to appear only in the axioms, not in the input formulas to be checked for satisfiability.
\end{definition}

Our goal is to develop a decision procedure for the quantifier-free fragment of $\mathcal{T}_E$. We will focus initially on deciding satisfiability for sets (or conjunctions) of literals, and then extend this to arbitrary quantifier-free formulas using normal forms.

\subsection{Normal Forms}

To handle arbitrary quantifier-free formulas, we introduce two important normal forms that facilitate systematic reasoning.

\subsubsection{Negation Normal Form (NNF)}

\begin{definition}[Negation Normal Form]
A formula is in \textbf{Negation Normal Form (NNF)} if:
\begin{itemize}
    \item The only logical connectives are $\wedge$, $\vee$, and $\neg$
    \item Negation ($\neg$) applies only to atomic formulas (atoms)
\end{itemize}
\end{definition}

Any quantifier-free formula can be converted to NNF by applying the following equivalence-preserving transformations:

\begin{align*}
H \leftrightarrow G &\equiv (H \rightarrow G) \wedge (G \rightarrow H) && \text{(Eliminate biconditional)} \\
H \rightarrow G &\equiv \neg H \vee G && \text{(Eliminate implication)} \\
\neg (H \wedge G) &\equiv \neg H \vee \neg G && \text{(De Morgan's law)} \\
\neg (H \vee G) &\equiv \neg H \wedge \neg G && \text{(De Morgan's law)} \\
\neg \neg H &\equiv H && \text{(Double negation elimination)}
\end{align*}

\subsubsection{Disjunctive Normal Form (DNF)}

\begin{definition}[Disjunctive Normal Form]
A formula is in \textbf{Disjunctive Normal Form (DNF)} if it is a disjunction of conjunctions of literals:
\[
\bigvee_{i=1}^{k} \left( \bigwedge_{j=1}^{n_i} L_{i,j} \right)
\]
where each $L_{i,j}$ is a literal (an atomic formula or its negation).
\end{definition}

Equivalently, a DNF formula has the structure:
\[
(L_{1,1} \wedge L_{1,2} \wedge \cdots \wedge L_{1,n_1}) \vee (L_{2,1} \wedge L_{2,2} \wedge \cdots \wedge L_{2,n_2}) \vee \cdots \vee (L_{k,1} \wedge L_{k,2} \wedge \cdots \wedge L_{k,n_k})
\]

\subsection{Conversion to DNF}

Any quantifier-free formula $F$ can be systematically converted to an equivalent DNF formula through a two-stage process:

\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (F) {$F$};
    \node (NNF) [rectangle, draw, right of=F, node distance=3cm] {Convert to NNF};
    \node (Fprime) [right of=NNF, node distance=3cm] {$F'$};
    \node (DNF) [rectangle, draw, right of=Fprime, node distance=3cm] {Convert to DNF};
    \node (Fdoubleprime) [right of=DNF, node distance=3cm] {$F''$};
    
    \draw[->] (F) -- (NNF);
    \draw[->] (NNF) -- (Fprime);
    \draw[->] (Fprime) -- (DNF);
    \draw[->] (DNF) -- (Fdoubleprime);
\end{tikzpicture}
\end{center}

\textbf{Stage 1}: Convert $F$ to NNF using the transformations above, obtaining $F'$.

\textbf{Stage 2}: Convert $F'$ to DNF by repeatedly applying the distributivity law:
\[
H \wedge (G_1 \vee G_2) \equiv (H \wedge G_1) \vee (H \wedge G_2)
\]

This transformation pushes conjunctions inward and disjunctions outward, resulting in a disjunction of conjunctions.

\subsection{Decision Procedure for Quantifier-Free $\mathcal{T}_E$}

The decision procedure operates on conjunctions of literals. Given a set (or conjunction) $S$ of literals:

\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (input) {$S$ (conjunction of literals)};
    \node (procedure) [rectangle, draw, right of=input, node distance=5cm] {Decision Procedure for $\text{QF}\mathcal{T}_E$};
    \node (unsat) [below right of=procedure, node distance=3cm] {\textbf{Unsatisfiable}};
    \node (sat) [above right of=procedure, node distance=3cm] {\textbf{Satisfiable}};
    
    \draw[->] (input) -- (procedure);
    \draw[->] (procedure) -- node[near start, above] {} (sat);
    \draw[->] (procedure) -- node[near start, below] {} (unsat);
\end{tikzpicture}
\end{center}

\textbf{Extension to arbitrary quantifier-free formulas}: For a general quantifier-free formula $F$:
\begin{enumerate}
    \item Convert $F$ to NNF, obtaining $F'$
    \item Convert $F'$ to DNF, obtaining $F'' = \bigvee_{i=1}^{k} C_i$ where each $C_i$ is a conjunction of literals
    \item Apply the decision procedure to each conjunction $C_i$
    \item $F$ is satisfiable if and only if at least one $C_i$ is satisfiable
\end{enumerate}

This reduction allows us to decide satisfiability for arbitrary quantifier-free formulas by deciding satisfiability for each disjunct independently.

\subsection{Elimination of Non-Equality Predicates}

The decision procedure for quantifier-free $\mathcal{T}_E$ assumes that the only predicate symbol in the formula is equality ($=$). However, formulas may contain additional predicate symbols. We now show how to eliminate such predicates through a satisfiability-preserving transformation.

\subsubsection{The Transformation}

\begin{definition}[Predicate Elimination]
Given an occurrence of a predicate symbol $P$ of arity $n$ applied to terms $t_1, \dots, t_n$, we eliminate $P$ by introducing:
\begin{itemize}
    \item A fresh function symbol $f_P$ (one for each predicate symbol $P \neq {=}$)
    \item A fresh constant symbol $\bullet$ (the same constant for all predicates)
\end{itemize}

The transformation replaces predicate applications with equality constraints:
\begin{align*}
P(t_1, \dots, t_n) &\mapsto f_P(t_1, \dots, t_n) = \bullet \\
\neg P(t_1, \dots, t_n) &\mapsto f_P(t_1, \dots, t_n) \neq \bullet
\end{align*}
\end{definition}

\textbf{Intuition}: The predicate $P(t_1, \dots, t_n)$ is true if and only if the term $f_P(t_1, \dots, t_n)$ evaluates to the distinguished constant $\bullet$.

\subsubsection{Satisfiability Preservation}

\begin{theorem}[Satisfiability Preservation]
Let $F$ be a quantifier-free formula and let $F'$ be the result of applying predicate elimination to $F$. Then $F$ is satisfiable if and only if $F'$ is satisfiable in models with cardinality greater than 1.
\end{theorem}

\begin{remark}
The restriction to models with cardinality greater than 1 is necessary to avoid trivial models. In a model with domain $D = \{d\}$ (cardinality 1), all terms evaluate to the same element $d$, making all equalities trivially true and potentially invalidating the transformation.
\end{remark}

\subsubsection{Example: The Need for Cardinality Restriction}

Consider the following two formulas:

\textbf{Original formula}:
\[
S_1 = \{\forall x \, \forall y \, (x = y), \neg P(a)\}
\]

This formula is $\mathcal{T}_E$-satisfiable. We can construct a model with domain $D = \{d_1, d_2\}$ where:
\begin{itemize}
    \item $\Phi(a) = d_1$
    \item $\Phi(P) = \{d_2\}$ (so $d_1 \notin \Phi(P)$, making $\neg P(a)$ true)
    \item The first axiom $\forall x \, \forall y \, (x = y)$ is vacuously false in this model, but if we interpret it as requiring equality to be universal, we need a different construction
\end{itemize}

Actually, let's reconsider: $\{\forall x \, \forall y \, (x = y), \neg P(a)\}$ asserts that all elements are equal (domain has cardinality 1) and $P(a)$ is false. This is satisfiable in a model with $D = \{d\}$, $\Phi(a) = d$, and $\Phi(P) = \emptyset$.

\textbf{Transformed formula}:
\[
S_2 = \{\forall x \, \forall y \, (x = y), f_P(a) \neq \bullet\}
\]

In a model with cardinality 1, we have $D = \{d\}$, so $\Phi(f_P)(d) = d$ and $\Phi(\bullet) = d$. Therefore, $f_P(a) = \bullet$, contradicting $f_P(a) \neq \bullet$. Thus $S_2$ is unsatisfiable in models of cardinality 1.

This example demonstrates that the transformation preserves satisfiability only when we exclude trivial models with cardinality 1.

\subsection{Treatment of Free Variables}

In quantifier-free formulas, free variables may appear. For the purposes of satisfiability checking, free variables are treated analogously to constants.

\begin{remark}[Free Variables as Constants]
To determine satisfiability of a formula $F$ with free variables $x_1, \dots, x_k$, we need to find an interpretation $\mathcal{I}$ and an assignment $\beta$ such that $\mathcal{I} \models_\beta F$.

Equivalently, we can treat each free variable $x_i$ as a fresh constant symbol $c_i$ and check satisfiability of the resulting closed formula. The formula is satisfiable if and only if there exist domain elements that can be assigned to these constants to satisfy the formula.
\end{remark}

This observation allows us to reduce the satisfiability problem for formulas with free variables to the satisfiability problem for closed formulas by a simple syntactic substitution.

\section{The Congruence Closure Algorithm}

\subsection{Motivating Example}

Consider the following conjunction of literals:
\[
x = g(x) \wedge f(x, g(g(x))) \neq g(x) \wedge f(x, x) = g(g(x))
\]

\textbf{Question}: Is this formula satisfiable or unsatisfiable?

\textbf{Intuitive analysis}: This formula appears to be unsatisfiable. From $x = g(x)$, we can derive $g(x) = g(g(x))$ by applying the function $g$ to both sides (congruence). Then from $f(x, x) = g(g(x))$ and the derived equality $g(x) = g(g(x))$, we obtain $f(x, x) = g(x)$. But we also have $x = g(x)$, so by congruence on $f$, we get $f(x, x) = f(x, g(x))$. However, we need to check whether $f(x, g(g(x))) = g(x)$ follows from the positive equalities, which would contradict $f(x, g(g(x))) \neq g(x)$.

\subsection{The Congruence Closure Decision Procedure}

The \textbf{congruence closure algorithm} is a decision procedure for satisfiability in the quantifier-free fragment of the theory of equality. The algorithm operates as follows:

\begin{enumerate}
    \item \textbf{Build the smallest congruence}: Construct the smallest congruence relation that satisfies all positive equalities in the input formula
    \item \textbf{Check negative equalities}: For each negative equality $s \neq t$ in the input, check whether $s$ and $t$ belong to the same equivalence class in the congruence
    \item \textbf{Determine satisfiability}:
    \begin{itemize}
        \item If any pair $(s, t)$ with $s \neq t$ belongs to the same equivalence class, the formula is \textbf{unsatisfiable}
        \item Otherwise, the congruence provides a model, and the formula is \textbf{satisfiable}
    \end{itemize}
\end{enumerate}

The key insight is that the smallest congruence containing all positive equalities is included in every congruence that satisfies those equalities. Therefore, if a negative equality is violated in the smallest congruence, it must be violated in every model.

\subsection{Equivalence Relations and Partitions}

Before describing the algorithm in detail, we recall fundamental properties of equivalence relations.

\begin{definition}[Equivalence Relation]
An \textbf{equivalence relation} $R$ on a set $S$ is a binary relation that is:
\begin{itemize}
    \item \textbf{Reflexive}: $\forall s \in S, \, s \, R \, s$
    \item \textbf{Symmetric}: $\forall s, t \in S, \, s \, R \, t \implies t \, R \, s$
    \item \textbf{Transitive}: $\forall s, t, u \in S, \, (s \, R \, t \wedge t \, R \, u) \implies s \, R \, u$
\end{itemize}
\end{definition}

\begin{definition}[Equivalence Class]
Given an equivalence relation $R$ on set $S$, the \textbf{equivalence class} of an element $s \in S$ is:
\[
[s]_R = \{s' \in S \mid s' \, R \, s\}
\]
\end{definition}

\begin{definition}[Quotient Set]
The \textbf{quotient set} $S/R$ is the set of all equivalence classes:
\[
S/R = \{[s]_R \mid s \in S\}
\]
\end{definition}

\begin{proposition}[Partition Property]
An equivalence relation $R$ on $S$ induces a partition of $S$. That is, for any two distinct equivalence classes $[s]_R$ and $[p]_R$:
\[
s \not\sim_R p \quad \implies \quad [s]_R \cap [p]_R = \emptyset
\]
where $s \sim_R p$ denotes $s \, R \, p$.

Conversely, every element belongs to exactly one equivalence class, and the union of all equivalence classes equals $S$.
\end{proposition}

This partition property is fundamental to the congruence closure algorithm, as it allows us to represent the congruence relation efficiently using a union-find data structure.

\newpage

\part{Decision Procedures for Quantifier-Free Theories}

\section{The Congruence Closure Algorithm}

\subsection{Computing Congruence Closure}

We now describe how to compute the congruence closure for the quantifier-free fragment of the theory of equality $\mathcal{T}_E$.

\subsubsection{Input Problem Structure}

Consider an input formula $F$ consisting of a conjunction of equality and disequality literals:
\[
F = \underbrace{\{s_1 = t_1, \dots, s_n = t_n\}}_{F^+} \cup \underbrace{\{s_{n+1} \neq t_{n+1}, \dots, s_{n+m} \neq t_{n+m}\}}_{F^-}
\]

where:
\begin{itemize}
    \item $F^+$ denotes the set of \textbf{positive equalities} (equations)
    \item $F^-$ denotes the set of \textbf{negative equalities} (disequations)
\end{itemize}

The congruence closure algorithm will construct the smallest congruence containing all equalities in $F^+$, then check whether any disequality in $F^-$ is violated.

\subsubsection{Equivalence Relations and Representatives}

Given a binary equivalence relation $R \subseteq S \times S$ on a set $S$, we can construct its quotient:
\[
S/R = \{[s]_R \mid s \in S\}
\]

where the equivalence class of $s$ is:
\[
[s]_R = \{p \in S \mid p \, R \, s\}
\]

The element $s$ is called a \textbf{representative} of the equivalence class $[s]_R$.

\subsubsection{Disjointness of Equivalence Classes}

\begin{proposition}[Disjoint Classes]
For any two equivalence classes $[s_1]_R$ and $[s_2]_R$, either they are identical or they are disjoint:
\[
[s_1]_R \cap [s_2]_R \neq \emptyset \quad \implies \quad [s_1]_R = [s_2]_R
\]
\end{proposition}

\begin{proof}
Suppose there exists $p \in [s_1]_R \cap [s_2]_R$. Then:
\begin{itemize}
    \item $p \, R \, s_1$ (since $p \in [s_1]_R$)
    \item $p \, R \, s_2$ (since $p \in [s_2]_R$)
\end{itemize}

By symmetry and transitivity of $R$, we have $s_1 \, R \, s_2$. Therefore, for any $q \in [s_1]_R$, we have $q \, R \, s_1$ and $s_1 \, R \, s_2$, so by transitivity $q \, R \, s_2$, which means $q \in [s_2]_R$. Similarly, $[s_2]_R \subseteq [s_1]_R$. Thus $[s_1]_R = [s_2]_R$.
\end{proof}

\subsubsection{Example: Equivalence Closure}

Consider the binary relation:
\[
R = \{(a, b), (b, c), (d, d)\}
\]

We can visualize this as a directed graph:
\begin{center}
\begin{tikzpicture}[node distance=1.5cm, auto]
    \node (a) {$a$};
    \node (b) [right of=a] {$b$};
    \node (c) [right of=b] {$c$};
    \node (d) [right of=c, node distance=2.5cm] {$d$};
    
    \draw[->] (a) -- (b);
    \draw[->] (b) -- (c);
    \draw[->] (d) edge [loop right] (d);
\end{tikzpicture}
\end{center}

The \textbf{equivalence closure} $R^*$ of $R$ must include:
\begin{itemize}
    \item \textbf{Reflexivity}: $(a, a), (b, b), (c, c), (d, d)$
    \item \textbf{Symmetry}: $(b, a), (c, b)$
    \item \textbf{Transitivity}: $(a, c), (c, a)$
\end{itemize}

Thus:
\[
R^* = \{(a, a), (a, b), (a, c), (b, a), (b, b), (b, c), (c, a), (c, b), (c, c), (d, d)\}
\]

The quotient set is:
\[
S/R^* = \{\{a, b, c\}, \{d\}\}
\]

\begin{definition}[Equivalence Closure]
Given a binary relation $R$ on set $S$, the \textbf{equivalence closure} of $R$, denoted $R^*$, is the $\subseteq$-smallest equivalence relation such that:
\begin{enumerate}
    \item $R^*$ is an equivalence relation
    \item $R \subseteq R^*$
\end{enumerate}

Equivalently, $R^*$ is the intersection of all equivalence relations containing $R$.
\end{definition}

The equivalence closure can be computed by iteratively applying reflexivity, symmetry, and transitivity rules until a fixed point is reached.

\subsubsection{Understanding the $\subseteq$-Smallest Property}

\begin{proposition}[Minimality of Equivalence Closure]
Let $R$ be a binary relation and $R^*$ be its equivalence closure. For any equivalence relation $P$ such that $R \subseteq P$, we have $R^* \subseteq P$.
\end{proposition}

This means that $R^*$ is the \textbf{smallest} equivalence relation containing $R$ with respect to the subset ordering $\subseteq$.

\begin{definition}[Congruence Closure]
Given a binary relation $R$, the \textbf{congruence closure} of $R$, denoted $R^*_{\text{cong}}$, is the $\subseteq$-smallest relation such that:
\begin{enumerate}
    \item $R^*_{\text{cong}}$ is a congruence relation
    \item $R \subseteq R^*_{\text{cong}}$
\end{enumerate}
\end{definition}

A congruence relation is an equivalence relation that is preserved under function application: if $s_1 \sim t_1, \dots, s_n \sim t_n$, then $f(s_1, \dots, s_n) \sim f(t_1, \dots, t_n)$ for all function symbols $f$.

\subsubsection{Example: Refinement of Equivalence Relations}

To illustrate the concept of one equivalence relation being smaller (finer) than another, consider the following example on the natural numbers $\N$.

\textbf{Equivalence modulo 2}: Define the relation $\equiv_2 \subseteq \N \times \N$ by:
\[
n \equiv_2 m \quad \text{iff} \quad n \equiv m \pmod{2}
\]

This relation partitions $\N$ into two equivalence classes:
\begin{center}
\begin{tikzpicture}
    \draw (0,0) circle (2cm);
    \node at (0, 1.5) {$\N/{\equiv_2}$};
    \draw[dashed] (0,0) -- (0,-2);
    \node at (-0.7, 0.3) {$[0]_2$};
    \node at (-0.7, -0.3) {(even)};
    \node at (0.7, 0.3) {$[1]_2$};
    \node at (0.7, -0.3) {(odd)};
\end{tikzpicture}
\end{center}

\textbf{Equivalence modulo 4}: Define the relation $\equiv_4 \subseteq \N \times \N$ by:
\[
n \equiv_4 m \quad \text{iff} \quad n \equiv m \pmod{4}
\]

This relation partitions $\N$ into four equivalence classes:
\begin{center}
\begin{tikzpicture}
    \draw (0,0) circle (2cm);
    \node at (0, 2.3) {$\N/{\equiv_4}$};
    \draw[dashed] (0,0) -- (0,-2);
    \draw[dashed] (0,0) -- (2,0);
    \node at (-0.7, 0.7) {$[0]_4$};
    \node at (0.7, 0.7) {$[1]_4$};
    \node at (-0.7, -0.7) {$[2]_4$};
    \node at (0.7, -0.7) {$[3]_4$};
\end{tikzpicture}
\end{center}

\begin{proposition}[Refinement]
The relation $\equiv_4$ is a \textbf{refinement} of $\equiv_2$. That is:
\[
n \equiv_4 m \quad \implies \quad n \equiv_2 m
\]

However, the converse does not hold:
\[
n \equiv_2 m \quad \not\Rightarrow \quad n \equiv_4 m
\]
\end{proposition}

\begin{proof}
If $n \equiv_4 m$, then $n \equiv m \pmod{4}$, which means $n - m = 4k$ for some $k \in \mathbb{Z}$. Therefore, $n - m = 2(2k)$, so $n \equiv m \pmod{2}$, i.e., $n \equiv_2 m$.

For the converse, consider $n = 0$ and $m = 2$. Then $n \equiv_2 m$ (both are even), but $n \not\equiv_4 m$ (since $0 \equiv 0 \pmod{4}$ and $2 \equiv 2 \pmod{4}$).
\end{proof}

\textbf{Set-theoretic interpretation}: This means that $(n, m) \in {\equiv_4} \implies (n, m) \in {\equiv_2}$, so:
\[
{\equiv_4} \subseteq {\equiv_2}
\]

In this sense, $\equiv_4$ is \textbf{strictly smaller} than $\equiv_2$ (it is a proper subset), and provides a finer partition of $\N$.

\subsection{The Congruence Closure Decision Procedure}

We now return to the main problem: deciding satisfiability for a quantifier-free formula in the theory of equality.

\subsubsection{Algorithm Description}

Recall that the input formula $F$ has the form:
\[
F = \underbrace{\{s_1 = t_1, \dots, s_n = t_n\}}_{F^+} \cup \underbrace{\{s_{n+1} \neq t_{n+1}, \dots, s_{n+m} \neq t_{n+m}\}}_{F^-}
\]

The congruence closure algorithm proceeds as follows:

\begin{algorithm}[H]
\caption{Congruence Closure Decision Procedure}
\begin{algorithmic}[1]
\STATE \textbf{Input:} Formula $F = F^+ \cup F^-$
\STATE Compute the congruence closure $\text{CC}(F^+)$ of the positive equalities $F^+$
\STATE \textbf{for} $i = n+1$ to $n+m$ \textbf{do}
\STATE \quad \textbf{if} $(s_i, t_i) \in \text{CC}(F^+)$ \textbf{then}
\STATE \quad \quad \textbf{return} UNSATISFIABLE
\STATE \quad \textbf{end if}
\STATE \textbf{end for}
\STATE \textbf{return} SATISFIABLE
\end{algorithmic}
\end{algorithm}

\textbf{Step 1}: Compute $\text{CC}(F^+)$, the smallest congruence relation containing all pairs $(s_i, t_i)$ for $i = 1, \dots, n$.

\textbf{Step 2}: For each disequality $s_i \neq t_i$ in $F^-$ (where $n+1 \leq i \leq n+m$), check whether $(s_i, t_i)$ belongs to the same equivalence class in $\text{CC}(F^+)$.

\textbf{Step 3}: 
\begin{itemize}
    \item If $(s_j, t_j) \in \text{CC}(F^+)$ for some $j$ with $n+1 \leq j \leq n+m$, then $F$ is \textbf{unsatisfiable}
    \item Otherwise, $F$ is \textbf{satisfiable}
\end{itemize}

\begin{center}
\begin{tikzpicture}[node distance=3cm, auto]
    \node (input) {$F = F^+ \cup F^-$};
    \node (cc) [rectangle, draw, right of=input, node distance=4cm] {Compute $\text{CC}(F^+)$};
    \node (unsat) [below right of=cc, node distance=3.5cm] {\textbf{UNSATISFIABLE}};
    \node (sat) [above right of=cc, node distance=3.5cm] {\textbf{SATISFIABLE}};
    
    \draw[->] (input) -- (cc);
    \draw[->] (cc) -- (unsat);
    \draw[->] (cc) -- (sat);
\end{tikzpicture}
\end{center}

\subsubsection{Correctness of the Algorithm}

\begin{theorem}[Soundness and Completeness]
The congruence closure algorithm is sound and complete for deciding satisfiability in the quantifier-free fragment of $\mathcal{T}_E$.
\end{theorem}

\begin{proof}[Proof sketch]
\textbf{Soundness (Unsatisfiability)}: Suppose there exists $j$ with $n+1 \leq j \leq n+m$ such that $(s_j, t_j) \in \text{CC}(F^+)$. 

Since $\text{CC}(F^+)$ is the smallest congruence relation containing $F^+$, the pair $(s_j, t_j)$ must belong to \emph{every} congruence relation that contains $F^+$. 

Therefore, in any model $\mathcal{I}$ that satisfies all equalities in $F^+$, we must have $\mathcal{I} \models s_j = t_j$. But $F$ also contains $s_j \neq t_j$, so $\mathcal{I} \not\models s_j \neq t_j$. Thus, no model can satisfy both $F^+$ and $F^-$, making $F$ unsatisfiable.

\textbf{Completeness (Satisfiability)}: If $(s_i, t_i) \notin \text{CC}(F^+)$ for all $i$ with $n+1 \leq i \leq n+m$, then we can construct a model by interpreting the equivalence classes of $\text{CC}(F^+)$ as domain elements. This model satisfies all equalities in $F^+$ (by construction) and all disequalities in $F^-$ (since the terms belong to different equivalence classes).
\end{proof}

The key insight is that the congruence closure captures exactly those equalities that are \emph{forced} by the positive equalities in $F^+$ together with the congruence axioms of equality.

\subsection{Examples: Manual Execution}

We now illustrate the congruence closure algorithm with concrete examples.

\subsubsection{Notation and Setup}

For a formula $F$ of the form:
\[
F = \{s_1 = t_1, \dots, s_n = t_n\} \cup \{s_{n+1} \neq t_{n+1}, \dots, s_{n+m} \neq t_{n+m}\}
\]

we define $S_F$ as the \textbf{set of all terms} that appear in $F$.

\subsubsection{Example 1}

Consider the formula:
\[
F = \{x = g(x), \, f(x, x) = g(g(x)), \, f(x, g(g(x))) \neq g(x)\}
\]

The set of terms is:
\[
S_F = \{x, \, g(x), \, f(x, x), \, g(g(x)), \, f(x, g(g(x)))\}
\]

\textbf{Notation}:
\begin{itemize}
    \item $x$ is a \textbf{free variable symbol}
    \item $f$ is a \textbf{binary function symbol} (arity 2)
    \item $g$ is a \textbf{unary function symbol} (arity 1)
\end{itemize}

\textbf{Positive equalities}: $F^+ = \{x = g(x), \, f(x, x) = g(g(x))\}$

\textbf{Negative equalities}: $F^- = \{f(x, g(g(x))) \neq g(x)\}$

\subsubsection{Example 2}

Consider the formula:
\[
F = \{f(a, b) = a, \, f(f(a, b), b) \neq a\}
\]

The set of terms is:
\[
S_F = \{f(a, b), \, a, \, b, \, f(f(a, b), b)\}
\]

\textbf{Notation}:
\begin{itemize}
    \item $a, b$ are \textbf{constant symbols} (by convention)
    \item $f$ is a \textbf{binary function symbol}
\end{itemize}

\textbf{Positive equalities}: $F^+ = \{f(a, b) = a\}$

\textbf{Negative equalities}: $F^- = \{f(f(a, b), b) \neq a\}$

\begin{remark}[Free Variables vs. Constants]
In the quantifier-free fragment, all variables are free. From a semantic perspective, free variables and constants can be used interchangeably: both are interpreted as arbitrary elements of the domain. The distinction is purely syntactic.
\end{remark}

\subsubsection{Step-by-Step Execution for Example 1}

We now execute the congruence closure algorithm on Example 1:
\[
F = \{x = g(x), \, f(x, x) = g(g(x)), \, f(x, g(g(x))) \neq g(x)\}
\]

\textbf{Step 1: Initialize the partition}

Create a partition of $S_F$ where every term is in its own singleton equivalence class:
\[
\{\{x\}, \{g(x)\}, \{f(x, x)\}, \{g(g(x))\}, \{f(x, g(g(x)))\}\}
\]

\textbf{Step 2: Process positive equalities}

For each equality $(s_i = t_i) \in F^+$ (for all $i$ with $1 \leq i \leq n$):
\begin{itemize}
    \item Unite the equivalence class of $s_i$ with the equivalence class of $t_i$
    \item Unite the classes of all terms in $S_F$ that become congruent as a consequence of $s_i = t_i$
\end{itemize}

\textbf{Processing $x = g(x)$}:

Merge the classes $\{x\}$ and $\{g(x)\}$:
\[
\{\{x, g(x)\}, \{f(x, x)\}, \{g(g(x))\}, \{f(x, g(g(x)))\}\}
\]

Since $x = g(x)$, by congruence we derive $g(x) = g(g(x))$ (applying $g$ to both sides). Merge these classes:
\[
\{\{x, g(x), g(g(x))\}, \{f(x, x)\}, \{f(x, g(g(x)))\}\}
\]

\textbf{Processing $f(x, x) = g(g(x))$}:

Since $g(g(x)) \in \{x, g(x), g(g(x))\}$ and $f(x, x) \in \{f(x, x)\}$, merge these classes:
\[
\{\{x, g(x), g(g(x)), f(x, x)\}, \{f(x, g(g(x)))\}\}
\]

Now check for congruence: since $x \sim g(g(x))$ (both in the same class), we have:
\[
f(x, x) \sim f(x, g(g(x)))
\]

by the congruence property (both arguments are in the same equivalence classes). Merge these classes:
\[
\{\{x, g(x), g(g(x)), f(x, x), f(x, g(g(x)))\}\}
\]

\textbf{Step 3: Check negative equalities}

Check whether $(s_i, t_i) \in \text{CC}(F^+)$ for all $i$ with $n+1 \leq i \leq n+m$.

For the disequality $f(x, g(g(x))) \neq g(x)$:
\begin{itemize}
    \item $f(x, g(g(x))) \in \{x, g(x), g(g(x)), f(x, x), f(x, g(g(x)))\}$
    \item $g(x) \in \{x, g(x), g(g(x)), f(x, x), f(x, g(g(x)))\}$
\end{itemize}

Both terms are in the same equivalence class, so $(f(x, g(g(x))), g(x)) \in \text{CC}(F^+)$.

\textbf{Conclusion}: The formula $F$ is \textbf{UNSATISFIABLE}.


























\end{document}